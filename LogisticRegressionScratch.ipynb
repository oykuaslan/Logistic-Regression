{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age\n",
      "0         0       3    2  22.0\n",
      "1         1       1    1  38.0\n",
      "2         1       3    1  26.0\n",
      "3         1       1    1  35.0\n",
      "4         0       3    2  35.0\n",
      "(891, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('titanicdata.csv')\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-survived passengers:  549\n",
      "Number of survived passengers:  342\n"
     ]
    }
   ],
   "source": [
    "# Print the class distribution\n",
    "print(\"Number of non-survived passengers: \", df[df.Survived == 0].shape[0])\n",
    "print(\"Number of survived passengers: \", df[df.Survived == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/__init__.py:806: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return floored.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract X and y\n",
    "X = df.drop(['Survived'], axis=1).values\n",
    "y = df.Survived.values\n",
    "\n",
    "# Use train_test_split\n",
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size = 0.2, stratify = y_train1, random_state = 1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training:  569\n",
      "Negative Samples:  351\n",
      "Positive Samples:  218\n",
      "Shape of validation:  143\n",
      "Negative Samples:  88\n",
      "Positive Samples:  55\n",
      "Shape of test:  179\n",
      "Negative Samples:  110\n",
      "Positive Samples:  69\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training: \", X_train.shape[0])\n",
    "print(\"Negative Samples: \", y_train[y_train == 0].shape[0])\n",
    "print(\"Positive Samples: \", y_train[y_train == 1].shape[0])\n",
    "\n",
    "\n",
    "print(\"Shape of validation: \", X_val.shape[0])\n",
    "print(\"Negative Samples: \", y_val[y_val == 0].shape[0])\n",
    "print(\"Positive Samples: \", y_val[y_val == 1].shape[0])\n",
    "\n",
    "\n",
    "print(\"Shape of test: \", X_test.shape[0])\n",
    "print(\"Negative Samples: \", y_test[y_test == 0].shape[0])\n",
    "print(\"Positive Samples: \", y_test[y_test == 1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "\n",
    "scale.fit(X_train)\n",
    "\n",
    "X_train = scale.transform(X_train)\n",
    "X_val = scale.transform(X_val)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, y_hat):\n",
    "    \n",
    "    #dw = (1/X.shape[0])*np.dot(X.T, (y_hat - y))\n",
    "    #db = (1/X.shape[0])*np.sum((y_hat - y)) \n",
    "    \n",
    "    dw = (1/X.shape[0])*np.dot(X.T, (y - y_hat))\n",
    "    db = (1/X.shape[0])*np.sum((y - y_hat)) \n",
    "    \n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs, lr):\n",
    "\n",
    "    n_samples, n_features= X.shape\n",
    "    w=np.zeros(n_features)\n",
    "    b=0\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "            \n",
    "        linear=(np.dot(X, w) + b)\n",
    "        y_hat = sigmoid(linear)\n",
    "            \n",
    "        dw, db = gradient(X, y, y_hat)\n",
    "            \n",
    "        w += lr*dw\n",
    "        b += lr*db\n",
    "                \n",
    "        loss = 1/n_samples * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1-y_hat))\n",
    "        losses.append(loss)\n",
    "                \n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,w,b):\n",
    "    \n",
    "    linear=(np.dot(X, w) + b)\n",
    "    preds = sigmoid(linear)\n",
    "    \n",
    "    pred_class = []\n",
    "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "    \n",
    "    return np.array(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=[10,50,100,150,200,250,300,350,400,450,500,1000,1500,2000]\n",
    "lr=[0.5,0.4,0.3,0.2, 0.1,0.001,0.001,0.0001,0.05,0.005,0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Learning Rate:  0.5 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.4 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.3 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.2 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.1 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.05 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  10 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  50 Learning Rate:  0.4 Accuracy:  0.8251748251748252\n",
      "Epoch:  50 Learning Rate:  0.3 Accuracy:  0.8251748251748252\n",
      "Epoch:  50 Learning Rate:  0.2 Accuracy:  0.7342657342657343\n",
      "Epoch:  50 Learning Rate:  0.1 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.05 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  50 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  100 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  100 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  100 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  100 Learning Rate:  0.2 Accuracy:  0.8251748251748252\n",
      "Epoch:  100 Learning Rate:  0.1 Accuracy:  0.7342657342657343\n",
      "Epoch:  100 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  100 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  100 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  100 Learning Rate:  0.05 Accuracy:  0.6153846153846154\n",
      "Epoch:  100 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  100 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  150 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  150 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  150 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  150 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  150 Learning Rate:  0.1 Accuracy:  0.8251748251748252\n",
      "Epoch:  150 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  150 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  150 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  150 Learning Rate:  0.05 Accuracy:  0.7342657342657343\n",
      "Epoch:  150 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  150 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  200 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  200 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  200 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  200 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  200 Learning Rate:  0.1 Accuracy:  0.8251748251748252\n",
      "Epoch:  200 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  200 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  200 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  200 Learning Rate:  0.05 Accuracy:  0.7342657342657343\n",
      "Epoch:  200 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  200 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  250 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  250 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  250 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  250 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  250 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  250 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  250 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  250 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  250 Learning Rate:  0.05 Accuracy:  0.8251748251748252\n",
      "Epoch:  250 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  250 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  300 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  300 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  300 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  300 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  300 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  300 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  300 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  300 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  300 Learning Rate:  0.05 Accuracy:  0.8251748251748252\n",
      "Epoch:  300 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  300 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  350 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  350 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  350 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  350 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  350 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  350 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  350 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  350 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  350 Learning Rate:  0.05 Accuracy:  0.8251748251748252\n",
      "Epoch:  350 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  350 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  400 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  400 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  400 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  400 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  400 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  400 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  400 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  400 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  400 Learning Rate:  0.05 Accuracy:  0.8251748251748252\n",
      "Epoch:  400 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  400 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  450 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  450 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  450 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  450 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  450 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  450 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  450 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  450 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  450 Learning Rate:  0.05 Accuracy:  0.8181818181818182\n",
      "Epoch:  450 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  450 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  500 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  500 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  500 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  500 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  500 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  500 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  500 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  500 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  500 Learning Rate:  0.05 Accuracy:  0.8181818181818182\n",
      "Epoch:  500 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  500 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  1000 Learning Rate:  0.5 Accuracy:  0.8181818181818182\n",
      "Epoch:  1000 Learning Rate:  0.4 Accuracy:  0.8181818181818182\n",
      "Epoch:  1000 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  1000 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  1000 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  1000 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  1000 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  1000 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  1000 Learning Rate:  0.05 Accuracy:  0.8181818181818182\n",
      "Epoch:  1000 Learning Rate:  0.005 Accuracy:  0.6153846153846154\n",
      "Epoch:  1000 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  1500 Learning Rate:  0.5 Accuracy:  0.8111888111888111\n",
      "Epoch:  1500 Learning Rate:  0.4 Accuracy:  0.8111888111888111\n",
      "Epoch:  1500 Learning Rate:  0.3 Accuracy:  0.8181818181818182\n",
      "Epoch:  1500 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  1500 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  1500 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  1500 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  1500 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  1500 Learning Rate:  0.05 Accuracy:  0.8181818181818182\n",
      "Epoch:  1500 Learning Rate:  0.005 Accuracy:  0.7342657342657343\n",
      "Epoch:  1500 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n",
      "Epoch:  2000 Learning Rate:  0.5 Accuracy:  0.8111888111888111\n",
      "Epoch:  2000 Learning Rate:  0.4 Accuracy:  0.8111888111888111\n",
      "Epoch:  2000 Learning Rate:  0.3 Accuracy:  0.8111888111888111\n",
      "Epoch:  2000 Learning Rate:  0.2 Accuracy:  0.8181818181818182\n",
      "Epoch:  2000 Learning Rate:  0.1 Accuracy:  0.8181818181818182\n",
      "Epoch:  2000 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  2000 Learning Rate:  0.001 Accuracy:  0.6153846153846154\n",
      "Epoch:  2000 Learning Rate:  0.0001 Accuracy:  0.6153846153846154\n",
      "Epoch:  2000 Learning Rate:  0.05 Accuracy:  0.8181818181818182\n",
      "Epoch:  2000 Learning Rate:  0.005 Accuracy:  0.7342657342657343\n",
      "Epoch:  2000 Learning Rate:  0.0005 Accuracy:  0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "for i in epochs:\n",
    "    for j in lr:\n",
    "        w, b,losses= train(X_train, y_train,i,j)\n",
    "        prediction=predict(X_val,w,b)\n",
    "        print(\"Epoch: \" ,i, \"Learning Rate: \", j, \"Accuracy: \" ,accuracy_score(prediction,y_val)\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "        #plt.plot(np.arange(i),losses)\n",
    "        #plt.xlabel(i)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50\n",
    "lr=0.3\n",
    "w, b,losses= train(X_train, y_train,epochs,lr)\n",
    "predictionTest=predict(X_test,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf889fa410>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(epochs),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictionTest,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
